import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

FEATURES = ["open","high","low","close","volume","rsi","ema_20","ema_50","macd","atr","bb_position","stoch_k","stoch_d","volume_ma_20","volume_ratio","obv","ad","vroc","rsi_overbought","price_above_bb","macd_negative_divergence","death_cross","volume_divergence"]


def calculate_sample_weights(y, price_changes):
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–µ—Å–∞ –¥–ª—è –æ–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫.
    
    FalsePositive (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ UP, –∞ –±—ã–ª–æ DOWN) ‚Äî –æ—á–µ–Ω—å –¥–æ—Ä–æ–≥–æ –≤ —Ç–æ—Ä–≥–æ–≤–ª–µ.
    FalseNegative (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ DOWN, –∞ –±—ã–ª–æ UP) ‚Äî —É–ø—É—â–µ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        y: —Ü–µ–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä (0=DOWN, 1=UP)
        price_changes: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —à—Ç—Ä–∞—Ñ–æ–≤)
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        weights: –≤–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
    """
    weights = np.ones(len(y))
    
    # FalsePositive (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ UP –∫–æ–≥–¥–∞ DOWN) ‚Äî —à—Ç—Ä–∞—Ñ –≤ 1.5x (–¥–æ—Ä–æ–≥–æ –≤ —Ç–æ—Ä–≥–æ–≤–ª–µ)
    # FalseNegative (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ DOWN –∫–æ–≥–¥–∞ UP) ‚Äî —à—Ç—Ä–∞—Ñ –≤ 1.2x (—É–ø—É—â–µ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å)
    # TruePositive –∏ TrueNegative ‚Äî –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –≤–µ—Å 1.0
    
    for i in range(len(y)):
        if y.iloc[i] == 0:  # –†–µ–∞–ª—å–Ω–æ –±—ã–ª–æ DOWN
            weights[i] = 1.5  # –®—Ç—Ä–∞—Ñ –∑–∞ FalsePositive –≤—ã—à–µ
        else:  # –†–µ–∞–ª—å–Ω–æ –±—ã–ª–æ UP
            weights[i] = 1.2  # –®—Ç—Ä–∞—Ñ –∑–∞ FalseNegative –º–µ–Ω—å—à–µ
    
    return weights


def calculate_simulated_pnl(y_true, y_pred, price_changes, starting_balance=1000):
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫, –µ—Å–ª–∏ –±—ã –º—ã —Å–ª–µ–¥–æ–≤–∞–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º –º–æ–¥–µ–ª–∏.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        y_true: —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (0=DOWN, 1=UP)
        y_pred: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (0=DOWN, 1=UP)
        price_changes: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –∑–∞ –ø–µ—Ä–∏–æ–¥
        starting_balance: –Ω–∞—á–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        final_balance: —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
        win_rate: –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        total_trades: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫
    """
    balance = starting_balance
    trades = 0
    wins = 0
    
    # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è numpy arrays –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    price_changes = np.array(price_changes)
    
    for i in range(len(y_true)):
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ UP, –æ—Ç–∫—Ä—ã–≤–∞–µ–º –ª–æ–Ω–≥
        if y_pred[i] == 1:
            trades += 1
            # –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–Ω–æ, –≤—ã–∏–≥—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
            if y_true[i] == 1 and price_changes[i] > 0:
                profit = balance * (abs(price_changes[i]) / 100)
                balance += profit
                wins += 1
            else:
                # –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ–≤–µ—Ä–Ω–æ, —Ç–µ—Ä—è–µ–º –ø–æ–ª–æ–≤–∏–Ω—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –≤—ã–∏–≥—Ä—ã—à–∞
                loss = balance * (abs(price_changes[i]) / 100) * 0.5
                balance -= loss
    
    if trades == 0:
        return balance, 0, 0
    
    win_rate = (wins / trades * 100)
    
    return balance, win_rate, trades


def train_model(df):
    df = df.copy()
    df["future_close"] = df["close"].shift(-1)
    df["target"] = (df["future_close"] > df["close"]).astype(int)
    
    # –†–∞—Å—á–∏—Ç–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —à—Ç—Ä–∞—Ñ–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ
    df["price_change_pct"] = ((df["future_close"] - df["close"]) / df["close"] * 100).fillna(0)
    
    df = df.dropna()

    X = df[FEATURES]
    y = df["target"]

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X_scaled = pd.DataFrame(X_scaled, columns=FEATURES, index=X.index)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)
    
    # –ü–æ–ª—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_indices = X_test.index
    price_changes_train = df.loc[X_train.index, "price_change_pct"]
    price_changes_test = df.loc[test_indices, "price_change_pct"]
    
    # –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–µ—Å–∞ –æ–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫
    sample_weights = calculate_sample_weights(y_train, price_changes_train)

    # –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å —Å —Ö–æ—Ä–æ—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–±–µ–∑ GridSearchCV –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
    print("–û–±—É—á–µ–Ω–∏–µ XGBoost —Å —Å–∏—Å—Ç–µ–º–æ–π —à—Ç—Ä–∞—Ñ–æ–≤...")
    model = xgb.XGBClassifier(
        n_estimators=150,
        max_depth=5,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=1,
        reg_alpha=0.1,
        reg_lambda=1.0,
        scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),
        random_state=42,
        n_jobs=-1,
        eval_metric='logloss',
        verbosity=0
    )
    
    # –û–±—É—á–∏—Ç—å —Å –≤–µ—Å–∞–º–∏ (—à—Ç—Ä–∞—Ñ—ã –∑–∞ –¥–æ—Ä–æ–≥–∏–µ –æ—à–∏–±–∫–∏)
    model.fit(X_train, y_train, sample_weight=sample_weights)

    accuracy = model.score(X_test, y_test)
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {accuracy:.4f}")
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è —á–µ—Å—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')
    print(f"–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (5 fold): —Å—Ä–µ–¥–Ω–µ–µ {cv_scores.mean():.4f}, –¥–∏–∞–ø–∞–∑–æ–Ω [{cv_scores.min():.4f}, {cv_scores.max():.4f}]")
    
    # –†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π P&L –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    y_pred_test = model.predict(X_test)
    
    try:
        final_balance, win_rate, total_trades = calculate_simulated_pnl(
            y_test.values, y_pred_test, price_changes_test.values, starting_balance=1000
        )
        
        print(f"\nüí∞ –°–∏–º—É–ª—è—Ü–∏—è —Ç–æ—Ä–≥–æ–≤–ª–∏ (–Ω–∞—á–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: $1000):")
        print(f"  –§–∏–Ω–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: ${final_balance:.2f}")
        print(f"  –ü—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫: ${final_balance - 1000:+.2f}")
        print(f"  Win rate: {win_rate:.1f}%")
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫: {total_trades}")
    except Exception as e:
        print(f"  (P&L —Ä–∞—Å—á—ë—Ç: {e})")
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å scaler –≤–º–µ—Å—Ç–µ —Å –º–æ–¥–µ–ª—å—é –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    model.scaler = scaler

    return model


def analyze_feature_importance(model, top_n=10):
    """–í—ã–≤–µ—Å—Ç–∏ –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–æ–¥–µ–ª–∏."""
    feature_importance = model.feature_importances_
    features_with_importance = list(zip(FEATURES, feature_importance))
    features_with_importance.sort(key=lambda x: x[1], reverse=True)
    
    print("\n–¢–æ–ø-–≤–∞–∂–Ω–µ–π—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
    for i, (feature, importance) in enumerate(features_with_importance[:top_n], 1):
        print(f"  {i}. {feature}: {importance:.4f}")
    
    return features_with_importance


def evaluate_model(model, df, test_size=0.2):
    """Evaluate trained `model` on the same split as `train_model`.

    Returns a dict with accuracy, precision, recall, f1 and confusion matrix.
    """
    df = df.copy()
    df["future_close"] = df["close"].shift(-1)
    df["target"] = (df["future_close"] > df["close"]).astype(int)
    df = df.dropna()

    X = df[FEATURES]
    y = df["target"]

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π scaler –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
    if hasattr(model, 'scaler'):
        X_scaled = model.scaler.transform(X)
        X_scaled = pd.DataFrame(X_scaled, columns=FEATURES, index=X.index)
    else:
        X_scaled = X

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, shuffle=False)

    if X_test.shape[0] == 0:
        return {"error": "no_test_data"}

    preds = model.predict(X_test)

    acc = accuracy_score(y_test, preds)
    prec = precision_score(y_test, preds, zero_division=0)
    rec = recall_score(y_test, preds, zero_division=0)
    f1 = f1_score(y_test, preds, zero_division=0)
    cm = confusion_matrix(y_test, preds)

    print("–û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (accuracy): {acc:.4f}")
    print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π '–í–≤–µ—Ä—Ö' (precision): {prec:.4f}")
    print(f"  –ü–æ–ª–Ω–æ—Ç–∞ –¥–ª—è '–í–≤–µ—Ä—Ö' (recall): {rec:.4f}")
    print(f"  F1 (—Å—Ä–µ–¥–Ω–µ–µ precision/recall): {f1:.4f}")
    
    # –ü—Ä–æ—Å—Ç–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –±–µ–∑ –º–∞—Ç—Ä–∏—Ü –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤
    tn, fp, fn, tp = cm.ravel()
    total = int(tn + fp + fn + tp)
    correct = int(tn + tp)
    incorrect = int(total - correct)

    print("–ö–æ—Ä–æ—Ç–∫–æ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö:")
    print(f"  –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞: {total}")
    print(f"  –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {correct} (‚âà{acc*100:.1f}%)")
    print(f"  –û—à–∏–±–æ–∫: {incorrect} (‚âà{(1-acc)*100:.1f}%)")

    # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –≤ –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª–æ–≤–∞—Ö
    predicted_up = int(tp + fp)
    actual_up = int(tp + fn)
    print("")
    print(f"  –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ '–í–≤–µ—Ä—Ö' {predicted_up} —Ä–∞–∑, –∏–∑ –Ω–∏—Ö {tp} —Ä–∞–∑ —ç—Ç–æ –æ–∫–∞–∑–∞–ª–æ—Å—å –≤–µ—Ä–Ω–æ, {fp} —Ä–∞–∑ ‚Äî –æ—à–∏–±–æ—á–Ω–æ.")
    print(f"  –í—Å–µ–≥–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ '–í–≤–µ—Ä—Ö' –±—ã–ª–æ {actual_up} —Ä–∞–∑, –º–æ–¥–µ–ª—å –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∞ (–Ω–µ –∑–∞–º–µ—Ç–∏–ª–∞) {fn} —Ç–∞–∫–∏—Ö —Å–ª—É—á–∞–µ–≤.")

    return {"accuracy": acc, "precision": prec, "recall": rec, "f1": f1, "confusion_matrix": cm}
