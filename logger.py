import pandas as pd
import json
from datetime import datetime
from pathlib import Path

class PredictionLogger:
    """–°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏."""
    
    def __init__(self, log_dir="logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # CSV –ª–æ–≥ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.csv_log = self.log_dir / "predictions.csv"
        self.ensure_csv_header()
        self.ensure_csv_columns()
    
    def ensure_csv_header(self):
        """–°–æ–∑–¥–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ CSV –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        if not self.csv_log.exists():
            header = pd.DataFrame(columns=self._expected_columns())
            header.to_csv(self.csv_log, index=False)

    def _expected_columns(self):
        return [
            'timestamp',
            'symbol',
            'prediction',
            'confidence',
            'close_price',
            'exit_price',
            'price_change_pct',
            'price_change_abs',
            'volume',
            'balance_simulated',
            'p_and_l',
            'accuracy',
            'win_rate',
            'horizon',
            'resolved',
            'actual_direction',
            'is_correct'
        ]

    def ensure_csv_columns(self):
        """Ensure CSV has all expected columns (upgrade old schema if needed)."""
        if not self.csv_log.exists():
            return
        try:
            header = pd.read_csv(self.csv_log, nrows=0)
            expected = self._expected_columns()
            missing = [c for c in expected if c not in header.columns]
            if not missing:
                return
            df = pd.read_csv(self.csv_log, on_bad_lines='skip', engine='python')
            for col in missing:
                df[col] = ""
            df = df.reindex(columns=expected)
            df.to_csv(self.csv_log, index=False)
        except Exception:
            return
    
    def log_prediction(self, symbol, prediction, confidence, close_price, volume, 
                      balance_simulated, p_and_l, accuracy, win_rate, horizon=1, timestamp=None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –æ–¥–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.
        
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            symbol: –Ω–∞–∑–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞ (BTC/USD, ETH/USD –∏ —Ç.–¥.)
            prediction: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (UP, DOWN, UNSURE)
            confidence: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (0-1)
            close_price: —Ü–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è
            volume: –æ–±—ä—ë–º
            balance_simulated: —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±–∞–ª–∞–Ω—Å
            p_and_l: –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫
            accuracy: —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
            win_rate: –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        """
        ts = timestamp if timestamp is not None else datetime.now().isoformat()
        log_data = {
            'timestamp': ts,
            'symbol': symbol,
            'prediction': prediction,
            'confidence': f"{confidence:.4f}",
            'close_price': f"{close_price:.2f}",
            'volume': f"{volume:.0f}",
            'balance_simulated': f"{balance_simulated:.2f}",
            'p_and_l': f"{p_and_l:.2f}",
            'accuracy': f"{accuracy:.4f}",
            'win_rate': f"{win_rate:.1f}%",
            'horizon': int(horizon),
            'resolved': 'False',
            'actual_direction': '',
            'is_correct': ''
        }
        
        # –î–æ–±–∞–≤–∏—Ç—å –≤ CSV —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º –∫–æ–ª–æ–Ω–æ–∫
        cols = self._expected_columns()
        df = pd.DataFrame([log_data]).reindex(columns=cols)
        df.to_csv(self.csv_log, mode='a', header=False, index=False, na_rep='')
        
        return log_data

    def resolve_predictions(self, symbol, df, horizon=1):
        """Resolve pending predictions based on future candles in df."""
        if not self.csv_log.exists() or df is None or len(df) == 0:
            return 0

        data = pd.read_csv(self.csv_log)
        if len(data) == 0:
            return 0

        if 'resolved' not in data.columns:
            return 0

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º timestamp –≤ datetime
        data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce')
        
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å
        for col in ['exit_price', 'price_change_pct', 'price_change_abs']:
            if col not in data.columns:
                data[col] = ""

        # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ—Ä–µ—à–µ–Ω–Ω—ã–µ –∏–ª–∏ –±–µ–∑ —Ä–∞—Å—á–µ—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        missing_change = (
            data['exit_price'].isna() | (data['exit_price'] == '') |
            data['price_change_pct'].isna() | (data['price_change_pct'] == '') |
            data['price_change_abs'].isna() | (data['price_change_abs'] == '')
        )

        pending_mask = (data['symbol'] == symbol) & (
            (data['resolved'].isna()) |
            (data['resolved'].astype(str).str.strip() != 'True') |
            (missing_change)
        )
        
        if pending_mask.sum() == 0:
            return 0

        df = df.copy()
        if 'time' not in df.columns:
            return 0
        
        df['time'] = pd.to_datetime(df['time'])
        df = df.sort_values('time').reset_index(drop=True)
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –æ–∫—Ä—É–≥–ª–µ–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω - –¥–æ –ß–ê–°–ê, —Ç.–∫. —Å–≤–µ—á–∏ —á–∞—Å–æ–≤—ã–µ!
        df['time_rounded'] = df['time'].dt.floor('h')  # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —á–∞—Å–∞
        
        resolved_count = 0
        
        for idx in data[pending_mask].index:
            ts = data.at[idx, 'timestamp']
            if pd.isna(ts):
                continue
            try:
                row_horizon = int(float(data.at[idx, 'horizon'])) if str(data.at[idx, 'horizon']).strip() != '' else horizon
            except Exception:
                row_horizon = horizon
            
            # –û–∫—Ä—É–≥–ª—è–µ–º timestamp –¥–æ –ß–ê–°–ê –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            ts_rounded = pd.Timestamp(ts).floor('h')
            
            # –ò—â–µ–º –±–ª–∏–∂–∞–π—à—É—é —Å–≤–µ—á—É (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö ¬±2 —á–∞—Å–æ–≤ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏)
            time_diff = (df['time_rounded'] - ts_rounded).abs()
            if time_diff.min() > pd.Timedelta(hours=2):
                continue  # –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å–≤–µ—á–∏
            
            i = time_diff.idxmin()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ horizon —Å–≤–µ—á–µ–π –≤–ø–µ—Ä–µ–¥
            # –ï—Å–ª–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–æ—Å—Ç—É–ø–Ω—É—é —Å–≤–µ—á—É (–æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ —ç—Ç–æ —Ç–µ–∫—É—â–∞—è)
            if i + row_horizon >= len(df):
                if i == len(df) - 1:  # –≠—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å–≤–µ—á–∞
                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–æ—Å—Ç—É–ø–Ω—É—é —Å–≤–µ—á—É –¥–ª—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
                    i_target = i
                else:
                    continue
            else:
                i_target = i + row_horizon
            
            entry = float(data.at[idx, 'close_price'])
            exit_price = float(df.iloc[i_target]['close'])
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            price_change_pct = ((exit_price - entry) / entry) * 100
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –ø–æ—Ä–æ–≥ (0.05%) —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —à—É–º–∞
            if price_change_pct > 0.05:
                actual_dir = "UP"
            elif price_change_pct < -0.05:
                actual_dir = "DOWN"
            else:
                actual_dir = "FLAT"  # –ù–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
            
            prediction = str(data.at[idx, 'prediction']).strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å (FLAT —Å—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫–æ–π)
            is_correct = (prediction == actual_dir) and actual_dir != "FLAT"

            data.loc[idx, 'resolved'] = True
            data.loc[idx, 'actual_direction'] = actual_dir
            data.loc[idx, 'is_correct'] = bool(is_correct)
            data.loc[idx, 'exit_price'] = exit_price
            data.loc[idx, 'price_change_pct'] = price_change_pct
            data.loc[idx, 'price_change_abs'] = exit_price - entry
            resolved_count += 1
            
            
            print(f"    ‚úì –†–∞–∑—Ä–µ—à–µ–Ω: {prediction} -> {actual_dir} ({price_change_pct:+.2f}%) = {'‚úÖ' if is_correct else '‚ùå'}")

        if resolved_count > 0:
            data.to_csv(self.csv_log, index=False)
            print(f"  üìä –†–∞–∑—Ä–µ—à–µ–Ω–æ {resolved_count} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è {symbol}")

        return resolved_count
    
    def log_session_summary(self, symbols, total_predictions, profitable_predictions):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∏—Ç–æ–≥–∏ —Å–µ—Å—Å–∏–∏."""
        summary = {
            'timestamp': datetime.now().isoformat(),
            'total_symbols': len(symbols),
            'symbols': ', '.join(symbols),
            'total_predictions': total_predictions,
            'profitable_predictions': profitable_predictions,
            'profitability_rate': f"{(profitable_predictions/total_predictions*100):.1f}%" if total_predictions > 0 else "0%"
        }
        
        summary_file = self.log_dir / f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        return summary
    
    def get_latest_predictions(self, symbol=None, limit=10):
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
        df = pd.read_csv(self.csv_log, on_bad_lines='skip', engine='python')
        
        if symbol:
            df = df[df['symbol'] == symbol]
        
        return df.tail(limit)
    
    def get_statistics(self, symbol=None):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–∏–º–≤–æ–ª—É –∏–ª–∏ –≤—Å–µ–º."""
        df = pd.read_csv(self.csv_log, on_bad_lines='skip', engine='python')
        
        if symbol:
            df = df[df['symbol'] == symbol]
        
        if len(df) == 0:
            return None
        
        stats = {
            'total_predictions': len(df),
            'symbols': df['symbol'].nunique(),
            'unique_symbols': df['symbol'].unique().tolist(),
            'avg_confidence': df['confidence'].astype(float).mean(),
            'up_predictions': len(df[df['prediction'] == 'UP']),
            'down_predictions': len(df[df['prediction'] == 'DOWN']),
            'unsure_predictions': len(df[df['prediction'] == 'UNSURE'])
        }
        
        return stats
